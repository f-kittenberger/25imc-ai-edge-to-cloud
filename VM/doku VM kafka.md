sudo apt update
sudo apt install -y docker.io docker-compose
sudo systemctl enable docker
sudo systemctl start docker


-->
canning linux images...                                                                                       

Running kernel seems to be up-to-date.

No services need to be restarted.

No containers need to be restarted.

No user sessions are running outdated binaries.

No VM guests are running outdated hypervisor (qemu) binaries on this host.


sudo usermod -aG docker $USER
logout
# neu einloggen


mkdir -p ~/kafka
cd ~/kafka

Schritt 4: docker-compose.yml erstellen
nano docker-compose.yml


Inhalt (IP ist deine feste IP):

version: "3.8"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.5.3
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      KAFKA_LISTENERS: INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://34.67.127.119:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    restart: unless-stopped


Speichern: Ctrl+O â†’ Enter â†’ Ctrl+X

Starten:
docker-compose up -d

logs ansehen:
docker-compose logs -f kafka


michael_aichinger_spitz@instance-20251109-123917:~/kafka$ grep KAFKA_ADVERTISED_LISTENERS docker-compose.yml
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://34.67.127.119:9092
michael_aichinger_spitz@instance-20251109-123917:~/kafka$ docker ps

CONTAINER ID   IMAGE                             COMMAND                  CREATED          STATUS          PORTS                                         NAMES
4ac878d47356   confluentinc/cp-kafka:7.5.3       "/etc/confluent/dockâ€¦"   12 minutes ago   Up 12 minutes   0.0.0.0:9092->9092/tcp, [::]:9092->9092/tcp   kafka_kafka_1
1f4b4c0f0505   confluentinc/cp-zookeeper:7.5.3   "/etc/confluent/dockâ€¦"   12 minutes ago   Up 12 minutes   2181/tcp, 2888/tcp, 3888/tcp                  kafka_zookeeper_1

die richtigen docker Bezeicghnungen einsetzen

5ï¸âƒ£ Die korrekte Art zu testen (sehr wichtig)
âœ… Test A: intern (Container â†’ Container)

Im Container immer den internen Listener verwenden:

docker exec -it kafka_kafka_1 \
kafka-topics --bootstrap-server kafka:29092 --list


ğŸ‘‰ NICHT localhost
ğŸ‘‰ NICHT die externe IP



Firewall fÃ¼r VM Kafka zulassen:

âœ… LÃ¶sung: Eine einzige Firewall-Regel erstellen

Wir machen das minimal, sauber, verstÃ¤ndlich.

ğŸ§± Ziel der Firewall-Regel

Erlaube:

TCP

Port 9092

von Ã¼berall (0.0.0.0/0)
â†’ nur fÃ¼r Kafka

1ï¸âƒ£ Neue Firewall-Regel erstellen

Google Cloud Console â†’

VPC network â†’ Firewall rules â†’ CREATE FIREWALL RULE

2ï¸âƒ£ Felder GENAU SO ausfÃ¼llen
ğŸ”¹ Name
allow-kafka-9092

ğŸ”¹ Netzwerk
default

ğŸ”¹ Traffic-Richtung
Eingehender Traffic

ğŸ”¹ Aktion bei Ãœbereinstimmung
Zulassen

ğŸ”¹ Ziele
Alle Instanzen im Netzwerk


(oder alternativ spÃ¤ter per Netzwerk-Tag â€“ fÃ¼r jetzt nicht nÃ¶tig)

ğŸ”¹ Quellfilter
IPv4-Bereiche

ğŸ”¹ Quell-IPv4-Bereiche
0.0.0.0/0


(ja, bewusst offen â€“ Kafka ist kein Webserver, spÃ¤ter kann man das einschrÃ¤nken)

ğŸ”¹ Protokolle und Ports

âŒ Alle zulassen â†’ NEIN

âœ… Angegebene Protokolle und Ports

Dann:

TCP
Ports:

9092

ğŸ”¹ Logs
Aus


(reicht vÃ¶llig)

ğŸ‘‰ Erstellen / Speichern


docker run -it --rm confluentinc/cp-kafka:7.5.3 \
kafka-console-producer \
--bootstrap-server 34.67.127.119:9092 \
--topic test

Wenn du jetzt:

>


siehst OHNE Warnungen â†’ ğŸ‰ ERFOLG

Tippe:

hello


Enter â†’ keine Fehlermeldung = perfekt.

Optional: Consumer-Test
docker run -it --rm confluentinc/cp-kafka:7.5.3 \
kafka-console-consumer \
--bootstrap-server 34.67.127.119:9092 \
--topic test \
--from-beginning

Ergebnis:
--> hello


Warum das alles logisch ist (wichtig fÃ¼rs VerstÃ¤ndnis)
Ebene	Status
Kafka	âœ… lÃ¤uft
Docker	âœ… korrekt
advertised.listeners	âœ… korrekt
Port-Mapping	âœ… korrekt
Firewall	âŒ blockiert
Ergebnis	âŒ externe Clients kommen nicht rein

Firewall-Regeln sind die letzte â€TÃ¼râ€œ.
Alles dahinter kann perfekt sein â€“ ohne Regel bleibt sie zu.

ğŸ”‘ Merksatz (sehr wichtig)

In Google Cloud:
Port offen im Container â‰  Port offen im Netzwerk.
Firewall entscheidet immer zuletzt.

ğŸš€ Definition of Done (nach diesem Schritt)


âœ” Kafka lÃ¤uft
âœ” Statische IP
âœ” EXTERNAL Listener
âœ” Firewall offen
âœ” Producer von auÃŸen verbindet

ğŸ‘‰ Ab hier ist Kafka produktionsbereit.

Laptop / Raspberry Pi
   â”‚
   â”‚  (TCP 9092)
   â–¼
Kafka (VM, Docker)
   â”‚
   â”‚  (internal)
   â–¼
Server / Consumer 

/home/michael/ai-edge-to-cloud/
â”œâ”€â”€ kafka/                # Kafka + Zookeeper (Docker Compose)
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ docker/               # Dockerfiles
â”‚   â””â”€â”€ Dockerfile.server
â”‚
â”œâ”€â”€ requirements/
â”‚   â””â”€â”€ server.txt
â”‚
â”œâ”€â”€ server/
â”‚   â””â”€â”€ main.py
â”‚
â””â”€â”€ logs/




Der Server ist:

âœ… Kafka Consumer

âœ… liest vom Topic test (oder spÃ¤ter people-detections)

âœ… speichert / hÃ¤lt letzten Wert im Speicher

âœ… stellt HTTP-Endpoint bereit (Flask)

âœ… wird spÃ¤ter:

von Browser

von Grafana

von Prometheus abgefragt

Noch kein Kubernetes.
Noch kein CI-Deploy.
Nur FunktionalitÃ¤t.

ğŸ”‘ Architektur-Merksatz (wichtig!)

Kafka = Infrastruktur
Server = Anwendung
Nie in denselben Ordner


