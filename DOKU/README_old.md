# AI Edge-to-Cloud System

## Project Overview
Dieses Projekt implementiert ein AI Edge-to-Cloud System, bei dem Edge-GerÃ¤te Daten Ã¼ber eine Kafka-basierte Pipeline an einen Server in der Cloud oder im lokalen Kubernetes-Cluster senden. Die Anwendung ermÃ¶glicht Echtzeit-Verarbeitung von Sensordaten und KI-Inferenz direkt am Edge sowie Aggregation und Monitoring in der Cloud.

## Architecture
- **Edge Device**: Generiert Sensordaten und fÃ¼hrt KI-Inferenz aus. Liefert Ergebnisse Ã¼ber Kafka.
- **Kafka**: Zentrale Event-Streaming-Plattform, die Edge-GerÃ¤te vom Server entkoppelt.
- **Server**: Konsumiert Kafka-Nachrichten, speichert die Daten und stellt REST-Endpunkte bereit.
- **Monitoring**: Optionales Modul fÃ¼r Visualisierung, Logging und Carbon-Aware Adaptation.

## Architecturally Significant Use Cases
1. **Person Detection at the Edge**  
   KI-basierte Analyse von Kameradaten direkt auf dem Edge-Device.
2. **Event Streaming via Kafka**  
   ZuverlÃ¤ssige, skalierbare Ãœbertragung von Ereignissen an den Server.
3. **Cloud-side Data Aggregation**  
   Konsolidierung und Speicherung eingehender Daten auf dem Server.
4. **Visualization and Monitoring**  
   Darstellung von Live-Daten fÃ¼r Monitoring und Analyse.
5. **Carbon-Aware Adaptation (geplant)**  
   Anpassung des Systems unter BerÃ¼cksichtigung von Energieverbrauch und COâ‚‚-Emissionen.

## Diagrams
- **Component Diagram**: Zeigt die einzelnen Module (Edge, Kafka, Server) und deren Schnittstellen.
- **Deployment Diagram**: Stellt dar, wie Komponenten in Kubernetes oder auf VMs bereitgestellt werden.
- **Sequence Diagrams**: Zeigt Datenfluss und Interaktionen fÃ¼r jeden Use Case.

## Deployment

### Local (Docker)
Stelle sicher, dass Docker APP lÃ¤uft.


eval $(minikube docker-env)
minikube start

docker build -f docker/Dockerfile.edge -t edge:latest .
docker build -f docker/Dockerfile.server -t server:latest .

### Kubernetes (Minikube)
### service entry added to kafka.yaml
kubectl apply -f k8s/kafka.yaml
kubectl apply -f k8s/server.yaml
kubectl apply -f k8s/edge.yaml
kubectl apply -f k8s/prometheus.yaml
kubectl apply -f k8s/grafana.yaml

kubectl get pods -A
kubectl get svc

kubectl logs -l app=edge -f
kubectl logs -l app=server -f
kubectl port-forward deployment/server 5000:5000
curl http://127.0.0.1:5000/data

k9s for overview
## Restart Pods e.g. server
kubectl delete pod -l app=server
minikube stop

## Manually push data for testing
curl -X POST http://localhost:5000/data -H "Content-Type: application/json" -d '{"persons_detected": 5, "device_id": "camera-01"}'

## Prometheus
kubectl port-forward svc/prometheus 9090:9090
visit http://127.0.0.1:9090/query

## Grafana
kubectl -n observability port-forward svc/grafana 3000:3000
http://127.0.0.1:3000/?orgId=1
User admin
PW admin (changed to edge-to-AI)

## Data Flow Overview

In the current setup, all data is transmitted via **Kafka**. The HTTP POST endpoint on the server is only used for optional testing or direct queries.
Edge Device
â”‚
â”‚ produces events
â–¼
Kafka Topic: edge-data
â”‚
â”‚ consumed by
â–¼
Server Application
â”‚
â”‚ stores and processes
â–¼
Data Store / Monitoring



- **Edge â†’ Kafka**: The edge devices produce inference results (person detection etc.) and send them to the Kafka topic `edge-data`.
- **Server â†’ Kafka**: The server consumes the `edge-data` topic using a Kafka consumer and appends the data to its internal store.
- **HTTP POST**: Only used optionally for debugging or testing, not part of the main production flow.

**Summary:** Kafka acts as the central event bus, decoupling edge and server components and ensuring a scalable, fault-tolerant communication channel.


Apache Kafka is used as a central event streaming platform to decouple edge devices from cloud services, enabling reliable, scalable, and fault-tolerant transmission of AI inference results.



âœ… FINAL RUNBOOK â€“ Edge â†’ Kafka â†’ Server (funktionierend)

Ziel:
Edge (K8s) sendet Daten â†’ Kafka (Docker Compose) â†’ Server (K8s) empfÃ¤ngt & verarbeitet

ğŸ”¹ 0. Voraussetzungen

Docker lÃ¤uft

Minikube lÃ¤uft

Projektverzeichnis: ~/ai-edge-to-cloud

ğŸ”¹ 1. Kafka + Zookeeper (Docker Compose, extern)
ğŸ“ Verzeichnis
cd ~/ai-edge-to-cloud/kafka-compose

â–¶ï¸ Start
docker compose down -v
docker compose up -d

âœ… PrÃ¼fen
docker ps


Erwartet:

kafka-compose-kafka-1

kafka-compose-zookeeper-1

ğŸ”¹ 2. Kafka-Konfiguration verifizieren (entscheidend!)
docker exec kafka-compose-kafka-1 bash -c 'env | grep ADVERTISED'


MUSS sein:

KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka:29092,EXTERNAL://192.168.49.2:9092

ğŸ”¹ 3. Kafka Topic anlegen
docker exec kafka-compose-kafka-1 kafka-topics \
  --bootstrap-server kafka:29092 \
  --create --if-not-exists \
  --topic edge-data \
  --partitions 1 \
  --replication-factor 1

PrÃ¼fen:
docker exec kafka-compose-kafka-1 kafka-topics \
  --bootstrap-server kafka:29092 --list


Erwartet:

edge-data

ğŸ”¹ 4. Minikube-IP ermitteln (fÃ¼r K8s)
minikube ip


ğŸ“Œ In deinem Fall:

192.168.49.2

ğŸ”¹ 5. Edge Deployment (Kubernetes)
k8s/edge.yaml
env:
  - name: BOOTSTRAP_SERVERS
    value: 192.168.49.2:9092

Anwenden + Neustart
cd ~/ai-edge-to-cloud
kubectl apply -f k8s/edge.yaml
kubectl delete pod -l app=edge

Logs prÃ¼fen
kubectl logs -l app=edge -f


Erwartet:

[EDGE] Sent: {...}

ğŸ”¹ 6. Server Deployment (Kubernetes)
k8s/server.yaml
env:
  - name: BOOTSTRAP_SERVERS
    value: 192.168.49.2:9092

Anwenden + Neustart
kubectl apply -f k8s/server.yaml
kubectl delete pod -l app=server

PrÃ¼fen: Env im Pod
kubectl exec -it $(kubectl get pod -l app=server -o jsonpath='{.items[0].metadata.name}') -- env | grep BOOTSTRAP


Erwartet:

BOOTSTRAP_SERVERS=192.168.49.2:9092

ğŸ”¹ 7. âœ… FINALER BEWEIS â€“ Server empfÃ¤ngt Kafka-Daten
kubectl logs -l app=server -f


ğŸ‰ Erwartet (Beweis):

[SERVER] Received via Kafka: {...}


â¡ï¸ Edge â†’ Kafka â†’ Server lÃ¤uft

ğŸ”¹ 8. (Optional) HTTP-Endpunkt prÃ¼fen
kubectl port-forward svc/server 5000:5000
curl http://localhost:5000/data


Erwartet:

[
  {
    "device_id": "edge-1",
    "timestamp": "...",
    "persons_detected": 24
  }
]

ğŸ§  Architektur-Entscheidung (fÃ¼r Doku / ADR)

Kafka auÃŸerhalb von Kubernetes

BegrÃ¼ndung:

stabileres lokales Setup

weniger Stateful-KomplexitÃ¤t

saubere Netzwerkgrenzen

realitÃ¤tsnah fÃ¼r Edge/Cloud-Szenarien

Kubernetes nutzt Kafka als externen Event-Bus

Komponente	LÃ¤uft wo?
Kafka	âŒ Minikube â†’ âœ… Docker (VM)
Zookeeper	âŒ Minikube â†’ âœ… Docker (VM)
Edge	âœ… Minikube
Server	âœ… Minikube
CI/CD	âœ… VM / GitHub
Verbindung	Minikube â†’ VM IP

âœ… Sauber alles runterfahren (ohne Datenverlust)
1ï¸âƒ£ Kubernetes / Minikube (falls noch lÃ¤uft)
minikube stop


(oder minikube delete, wenn du Speicher brauchst â€“ Code bleibt)

2ï¸âƒ£ Kafka & Zookeeper (Docker Compose)
cd ~/ai-edge-to-cloud/kafka-compose
docker compose down

3ï¸âƒ£ Docker generell beruhigen
docker ps


â¡ï¸ sollte leer sein oder nur Systemcontainer zeigen

Optional:

docker system prune



VM instanz starten

source ai-edge-venv/bin/activate

minicube start

cd ~/ai-edge-to-cloud/kafka-compose

docker compose down -v

docker compose up -d

docker ps

Erwartet:

kafka-compose-kafka-1

kafka-compose-zookeeper-1

ğŸ”¹ 2. Kafka-Konfiguration verifizieren (entscheidend!)
docker exec kafka-compose-kafka-1 bash -c 'env | grep ADVERTISED'


MUSS sein:

KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka:29092,EXTERNAL://192.168.49.2:9092

ğŸ”¹ 3. Kafka Topic anlegen
docker exec kafka-compose-kafka-1 kafka-topics \
  --bootstrap-server kafka:29092 \
  --create --if-not-exists \
  --topic edge-data \
  --partitions 1 \
  --replication-factor 1

PrÃ¼fen:
docker exec kafka-compose-kafka-1 kafka-topics \
  --bootstrap-server kafka:29092 --list
























--------------------------LauffÃ¤hig Kafka + zookeeper -----------------------------------

source ai-edge-venv/bin/activate


âœ… FINAL RUNBOOK (REPRODUZIERBAR & STABIL)

Edge (K8s) â†’ Kafka (Docker Compose extern) â†’ Server (K8s)

Ziel:
Egal wann, egal wie oft:
Du kannst alles lÃ¶schen, alles neu starten und es lÃ¤uft wieder.

ğŸ§  Architektur (fest, nicht mehr Ã¤ndern)
Komponente	LÃ¤uft wo
Kafka	Docker Compose (VM / Host)
Zookeeper	Docker Compose (VM / Host)
Edge	Kubernetes (Minikube)
Server	Kubernetes (Minikube)
Verbindung	K8s â†’ host.docker.internal:9092

â— Kafka lÃ¤uft NICHT in Kubernetes
â— K8s greift immer extern auf Kafka zu

ğŸ”’ GOLDENE REGELN (bitte merken)

Kafka-Ã„nderung â‰  K8s-Ã„nderung

ENV-Ã„nderung + imagePullPolicy: Never â‡’ IMMER neu bauen

Pods lÃ¶schen reicht NICHT â€“ Deployments cachen

Beweis ist immer: env im Pod

ğŸ§¹ 0. KOMPLETT RESET (wenn irgendwas komisch ist)
Kubernetes zurÃ¼cksetzen (optional, aber sauber)
minikube stop
minikube start

Docker sauber halten (optional)
docker system prune -f

ğŸŸ¢ 1. Kafka + Zookeeper STARTEN (Docker Compose)
cd ~/ai-edge-to-cloud/kafka-compose
docker compose down -v
docker compose up -d

PrÃ¼fen
docker ps


âœ… Erwartet:

kafka-compose-kafka-1
kafka-compose-zookeeper-1

ğŸ” 2. Kafka ADVERTISED LISTENERS PRÃœFEN (KRITISCH!)
docker exec kafka-compose-kafka-1 env | grep ADVERTISED


âœ… MUSS GENAU SO SEIN:

KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka:29092,EXTERNAL://host.docker.internal:9092


âŒ Wenn hier IP steht â†’ Kafka falsch konfiguriert â†’ STOP.

ğŸ“¦ 3. Kafka Topic anlegen
docker exec kafka-compose-kafka-1 kafka-topics \
  --bootstrap-server kafka:29092 \
  --create --if-not-exists \
  --topic edge-data \
  --partitions 1 \
  --replication-factor 1


PrÃ¼fen:

docker exec kafka-compose-kafka-1 kafka-topics \
  --bootstrap-server kafka:29092 --list


âœ… Erwartet:

edge-data

ğŸ³ 4. Docker-Umgebung fÃ¼r Minikube setzen (PFLICHT!)
eval $(minikube docker-env)


â— Ab jetzt werden Images INS Minikube gebaut

ğŸ— 5. IMAGES NEU BAUEN (IMMER!)
docker build -f docker/Dockerfile.edge -t edge:latest .
docker build -f docker/Dockerfile.server -t server:latest .


PrÃ¼fen:

docker images | grep -E "edge|server"

ğŸš€ 6. Kubernetes Deployments NEU AUFSETZEN
Server
kubectl delete deployment server --ignore-not-found
kubectl delete service server --ignore-not-found
kubectl apply -f k8s/server.yaml

Edge
kubectl delete deployment edge --ignore-not-found
kubectl apply -f k8s/edge.yaml

ğŸ” 7. ABSOLUTER BEWEIS â€“ ENV im Pod
Server
kubectl exec -it \
  $(kubectl get pod -l app=server -o jsonpath='{.items[0].metadata.name}') \
  -- env | grep BOOTSTRAP


âœ… MUSS SEIN

BOOTSTRAP_SERVERS=host.docker.internal:9092


Wenn nicht â†’ Image NICHT neu gebaut.

ğŸ“¡ 8. LOGS = FINALER BEWEIS
kubectl logs -l app=server -f


âœ… Erwartet (dein aktueller Beweis):

[SERVER] Kafka consumer started, bootstrap=host.docker.internal:9092
[SERVER] Received via Kafka: {...}


â¡ï¸ Pipeline lÃ¤uft. Punkt.

ğŸŒ 9. (Optional) HTTP prÃ¼fen
kubectl port-forward svc/server 5000:5000
curl http://localhost:5000/data

âš ï¸ Zur Warnung in deinen Logs (harmlos!)
Broker reports different ClusterId ...


â¡ï¸ Kommt von altem Consumer-Offset / Neustart
â¡ï¸ KEIN Fehler, Kafka synchronisiert sich neu
â¡ï¸ Kann ignoriert werden

ğŸ§¾ WAS DU JETZT HAST (fÃ¼r Abgabe)

âœ… Funktionierende Edgeâ†’Kafkaâ†’Server Pipeline
âœ… Externe Kafka-Architektur (realistisch, stabil)
âœ… K8s + Docker sauber getrennt
âœ… Reproduzierbares Runbook
âœ… ADR-fÃ¤hige Architekturentscheidung

ğŸ ABSCHLUSS

Du hast nichts â€falsch gemachtâ€œ.
Du bist genau an den Punkten hÃ¤ngen geblieben, an denen auch Profis hÃ¤ngen:

K8s Caching

Docker vs Minikube Docker

Kafka Advertised Listeners

Jetzt hast du das unter Kontrolle.